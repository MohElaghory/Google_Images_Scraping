{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "acb25e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "import time as t\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "import urllib\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac358951",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-487aaf8abc06>:9: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver= webdriver.Chrome(executable_path= 'animals//chromedriver.exe', options= chrome_options)   # open driver\n",
      "C:\\Users\\nooor\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:451: UserWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  warnings.warn(\"find_element_by_* commands are deprecated. Please use find_element() instead\")\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    os.mkdir(\"dataset_download\")            # make folder to download in it the scraping images\n",
    "except:\n",
    "    pass\n",
    "\n",
    "name= 'giraffe'\n",
    "chrome_options= webdriver.ChromeOptions()      # open google chrome session\n",
    "chrome_options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])        # this line prevent chrome from Annoying notifications\n",
    "driver= webdriver.Chrome(executable_path= 'animals//chromedriver.exe', options= chrome_options)   # open driver\n",
    "strr= 'https://www.google.com.eg/search?q=giraffe&hl=ar&authuser=0&tbm=isch&sxsrf=APq-WBtHQXs6QFL0J5ujB_e9YBDzGuuO-A%3A1650923225660&source=hp&biw=1366&bih=625&ei=2RZnYvSHJsr87_UP_9iX0Ak&iflsig=AHkkrS4AAAAAYmck6UI1asyZ8FlgzhJTOrzj281wNbnN&ved=0ahUKEwi02KijmLD3AhVK_rsIHX_sBZoQ4dUDCAc&uact=5&oq=giraffe&gs_lcp=CgNpbWcQAzIFCAAQgAQyBQgAEIAEMgUIABCABDIFCAAQgAQyBQgAEIAEMgUIABCABDIFCAAQgAQyBQgAEIAEMgUIABCABDIFCAAQgAQ6CggjEO8DEOoCECc6CAgAEIAEELEDOgkIABCABBAKEAE6CwgAEIAEELEDEIMBOgQIABAKOggIABCxAxCDAToECAAQHjoECAAQAjoECAAQEzoGCAAQBxAeULgPWOKlAmDCqwJoBXAAeACAAXeIAaILkgEEMTEuNJgBAKABAaABAqoBC2d3cy13aXotaW1nsAEK&sclient=img'\n",
    "driver.get(strr)    # connect to link\n",
    "t.sleep(3)         # براحتك scraping يعني استني 3 ثواني علي ما اللينك ده يفتح وبعد كده اعمل\n",
    "\n",
    "pics= driver.find_element_by_xpath('//*[@id=\"islrg\"]/div[1]')       # x_path for all image, this is the div which contain all images\n",
    "links= []\n",
    "x= 1\n",
    "last_height= 0\n",
    "\n",
    "def download_image(url, filename):              # this function to download images in specific folder and name ---> (filename)\n",
    "    resource= urllib.request.urlopen(url)       # to open url of image\n",
    "    output= open(filename, \"wb\")                # to write binary in the filename\n",
    "    output.write(resource.read())               # open url and write image in the filename in my local pc ---> (download image)\n",
    "    output.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daad25a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nooor\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webelement.py:432: UserWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  warnings.warn(\"find_elements_by_* commands are deprecated. Please use find_elements() instead\")\n",
      "C:\\Users\\nooor\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webelement.py:399: UserWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  warnings.warn(\"find_element_by_* commands are deprecated. Please use find_element() instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------6415\n",
      "-------------12965\n",
      "-----------------19512\n",
      "---------------------25820\n",
      "---------------------25901\n",
      "---------------------25901\n",
      "---------------------32604\n",
      "--------------------------38665\n",
      "----------------------------43111\n",
      "----------------------------43111\n",
      "----------------------------43111\n",
      "----------------------------43111\n",
      "----------------------------43111\n",
      "----------------------------43111\n",
      "----------------------------43111\n",
      "----------------------------43111\n",
      "----------------------------43111\n",
      "----------------------------43111\n",
      "----------------------------43111\n",
      "----------------------------43111\n",
      "----------------------------43111\n",
      "----------------------------43111\n",
      "----------------------------43111\n",
      "----------------------------43111\n",
      "----------------------------43111\n",
      "----------------------------43111\n",
      "----------------------------43111\n",
      "-------------------"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")       # scroll down all url to arrive to end of images page                  \n",
    "    t.sleep(4)      # علي ما الصور تحمل شويه scroll down استني 4 ثواني مع كل\n",
    "    pics_= pics.find_elements_by_xpath('./*')          # هيضم جميع الصور بداخله pics_ اللي اسمه variable الكامل بتاع كل الصور يعني ال xpath أنا هنا بجيب ال\n",
    "    \n",
    "    for pic in pics_:                # loop on every image (full x_path for every images) to get src link from each image\n",
    "        try:\n",
    "            img_link= pic.find_element_by_xpath('a[1]/div[1]/img').get_attribute('src')    # get src link from each image\n",
    "            \n",
    "            if img_link not in links:        # بأني بشوف هل الصور دي خدتها قبل كده ولا لا قبل ما اخدها تاني وده لان في صور متكرره فمخدهاش أكتر من مره check بعمل \n",
    "                links.append(img_link)\n",
    "                try:\n",
    "                    os.mkdir(\"dataset_download//\"+name)       # [giraffe] وهيعملي فولدر تاني اسمه [dataset_download] يعني هيدخل جوه الفولدر اللي اسمه\n",
    "                except:\n",
    "                    pass\n",
    "                \n",
    "                file_name= \"dataset_download//\"+ name + '//' + str(x) + '.jpg'        # x=1 بأني بدي جنب اسمها رقم بدايه من scrap بدي اسم لكل صوره بعملها\n",
    "                download_image(img_link, file_name)\n",
    "                \n",
    "                x+=1\n",
    "        except:\n",
    "            print('-', end= '')          # - عشان وانا بلف علي الصور وكان في صوره مش عايزه تنزل بسبب ان ليها حقوق ملكيه ولا حاجه فيحطلي مكان الصوره دي الشرطه دي except و try أنا هنا بعمل \n",
    "    \n",
    "    # بتجيب اخر الصفحه فبيبقي الرقم ده أكبر رقم scroll بتاعت الصفحه لما بتنزل كل مره بيبقي عباره عن رقم فلما ال scroll ال\n",
    "    new_height= driver.execute_script(\"return document.body.scrollHeight\")     # دلوقتي scroll ده الرقم اللي واقف فيه ال\n",
    "    print(new_height)     # كل مره scroll بقوله اطبعلي الرقم اللي واقف فيه ال\n",
    "    if new_height == last_height:     # وقت مابدأ تساوي برقمه لاخر الصفحه فبقوله خلاص وقف الكود لان ساعتها هيبقي الصفحه جابت اخرها scroll لو رقم ال\n",
    "        break\n",
    "    last_height == new_height         # ولو لسه مابقتش بتساوي الرقم اللي بدأت بيه فده معناه انها لسه ماجبتش اخرها فكمل نزول بالاسكورول\n",
    "    \n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57453911",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
